{"cells":[{"cell_type":"code","source":["import tensorflow as tf\n","device_name = tf.test.gpu_device_name()\n","if device_name != '/device:GPU:0':\n","  raise SystemError('GPU device not found')\n","print('Found GPU at: {}'.format(device_name))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":193},"id":"Ag3RAviu_hbR","executionInfo":{"status":"error","timestamp":1733126784943,"user_tz":480,"elapsed":8865,"user":{"displayName":"Victor Paul Portmann","userId":"02040331471509710257"}},"outputId":"403629f0-6b9e-42d1-fb79-4290500714f1"},"id":"Ag3RAviu_hbR","execution_count":null,"outputs":[{"output_type":"error","ename":"SystemError","evalue":"GPU device not found","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mSystemError\u001b[0m                               Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-d1680108c58e>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdevice_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgpu_device_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdevice_name\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'/device:GPU:0'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   \u001b[0;32mraise\u001b[0m \u001b[0mSystemError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'GPU device not found'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Found GPU at: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mSystemError\u001b[0m: GPU device not found"]}]},{"cell_type":"code","execution_count":null,"id":"e08abb23-3c34-4ecf-a738-07e200c48b8c","metadata":{"id":"e08abb23-3c34-4ecf-a738-07e200c48b8c"},"outputs":[],"source":["import numpy as np\n","import os\n","import matplotlib.pyplot as plt\n","import tensorflow.keras.layers as tfl\n","import tensorflow.keras.backend as K\n","from tensorflow.keras.applications import DenseNet169\n","from skimage.metrics import structural_similarity as ssim\n","from tensorflow.keras import backend as K\n","from tensorflow.keras.metrics import SparseCategoricalAccuracy"]},{"cell_type":"code","execution_count":null,"id":"82810e3f-7501-4b27-bbb7-769707b44351","metadata":{"id":"82810e3f-7501-4b27-bbb7-769707b44351"},"outputs":[],"source":["print(f'Using Keras version {tf.keras.__version__}')\n","print(f'Using TensorFlow version {tf.__version__}')"]},{"cell_type":"code","execution_count":null,"id":"8dee64ac","metadata":{"id":"8dee64ac"},"outputs":[],"source":["def shuffle_in_place(a, b, c):\n","    rng_state = np.random.get_state()\n","    np.random.shuffle(a)\n","    np.random.set_state(rng_state)\n","    np.random.shuffle(b)\n","    np.random.set_state(rng_state)\n","    np.random.shuffle(c)"]},{"cell_type":"code","execution_count":null,"id":"f5388808","metadata":{"id":"f5388808"},"outputs":[],"source":["CLASS_DICT = {\n","    0: 'car',\n","    1: 'trash container',\n","    2: \"bicycle\"\n","}\n","\n","def decode_class(cl_index):\n","    return CLASS_DICT[cl_index]"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"7g3BrzcfAGgC"},"id":"7g3BrzcfAGgC","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"id":"43068b52-4f38-4a0b-b849-5045ac35befe","metadata":{"id":"43068b52-4f38-4a0b-b849-5045ac35befe"},"outputs":[],"source":["# load the data and print some important information about it\n","X_orig = np.load('/content/drive/MyDrive/CS230 /Toy Data/X_NEW.npy')\n","Y_orig = np.load('/content/drive/MyDrive/CS230 /Toy Data/Y_NEW.npy')\n","classes = np.load('/content/drive/MyDrive/CS230 /Toy Data/Y_NEW_classes.npy')\n","\n","# resizing for the gradients loss fn\n","Y_shape = Y_orig.shape\n","Y_orig = np.resize(Y_orig, (Y_shape[0], Y_shape[1], Y_shape[2], 1))\n","\n","# shuffle the toyset\n","shuffle_in_place(X_orig, Y_orig, classes)\n","\n","X_train, X_test = X_orig, None\n","Y_train, Y_test = Y_orig, None\n","classes_train = classes\n","# classes_train = tf.reshape(tf.one_hot(classes_train, 3), shape=[600, 3])\n","\n","# normalize\n","X_train = tf.convert_to_tensor(X_train/255)\n","Y_train = tf.convert_to_tensor(Y_train/1000)\n","\n","print (\"number of training examples = \" + str(X_train.shape[0]))\n","\n","print (\"X_train shape: \" + str(X_train.shape))\n","print (\"Y_train shape: \" + str(Y_train.shape))\n","print(\"class vector shape: \" + str(classes_train.shape))\n","\n","# set the max depth value for the loss fn\n","MAX_DEPTH = np.max(Y_train) - np.min(Y_train)\n","print(f'MAX_DEPTH = {MAX_DEPTH}')\n","\n","# set the cmap\n","cmap='plasma_r'"]},{"cell_type":"code","execution_count":null,"id":"a219adff-02bc-4d4f-bf18-6df98b48949b","metadata":{"id":"a219adff-02bc-4d4f-bf18-6df98b48949b"},"outputs":[],"source":["# look at various images\n","image_num = 0\n","fig, arr = plt.subplots(1, 2, figsize=(14, 7))\n","arr[0].imshow(X_train[image_num])\n","arr[0].set_title(f'RGB Image')\n","arr[1].imshow(Y_train[image_num], cmap=cmap)\n","arr[1].set_title('Depth Image')\n","print(decode_class(classes_train[image_num][0]))"]},{"cell_type":"markdown","id":"1ffe5852-80c9-40b3-b119-a7cafe9050b6","metadata":{"id":"1ffe5852-80c9-40b3-b119-a7cafe9050b6"},"source":["### U NET ARCHITECHTURE ###\n","\n","1. Contracting Block (downsample/encode) --> using transfer learning from DenseNet169\n","2. Skip connection (Concatenation)\n","3. Expanding Block (upsample/decode)\n","4. Final Feature Mapping (1x1 conv)\n","\n","Used the framework from https://arxiv.org/abs/1812.11941"]},{"cell_type":"code","execution_count":null,"id":"7e014f98-0fb2-4451-9ef2-ec78855892fe","metadata":{"id":"7e014f98-0fb2-4451-9ef2-ec78855892fe"},"outputs":[],"source":["def UpScaleBlock(expansive_input, concat_layer, concat=True, n_filters=32):\n","    '''\n","    Convolutional upsampling block\n","\n","    Arguments:\n","        expansive_input -- input to be upsampled\n","        concat_layer -- skip connection from the previous layer\n","        concat (bool) -- whether or not to include the skip\n","        n_filters -- # of filters\n","    Returns:\n","        reluB -- upsampled relu output tensor\n","    '''\n","\n","    up = tfl.UpSampling2D(size=(2, 2), interpolation='bilinear')(expansive_input)\n","    if concat:\n","        concatenated = tfl.concatenate([up, concat_layer], axis=-1)\n","        convA = tfl.Conv2D(n_filters, kernel_size=3, strides=1, padding='same', kernel_initializer='he_normal')(concatenated)\n","    else:\n","        convA = tfl.Conv2D(n_filters, kernel_size=3, strides=1, padding='same')(up)\n","\n","    bnA = tfl.BatchNormalization()(convA)\n","    reluA = tfl.LeakyReLU(negative_slope=0.2)(bnA)\n","    convB = tfl.Conv2D(n_filters, kernel_size=3, strides=1, padding='same', kernel_initializer='he_normal')(reluA)\n","    bnB = tfl.BatchNormalization()(convB)\n","    reluB = tfl.LeakyReLU(negative_slope=0.2)(convB)\n","\n","    return reluB"]},{"cell_type":"code","source":["def calculate_ssim(y_true, y_pred):\n","    return ssim(y_true, y_pred, data_range=K.max(y_true)-K.min(y_true))"],"metadata":{"id":"fHUMXYUEpwNE"},"id":"fHUMXYUEpwNE","execution_count":null,"outputs":[]},{"cell_type":"code","source":["def ssim_metric(y_true, y_pred):\n","    return tf.py_function(calculate_ssim, [y_true, y_pred], tf.float32)"],"metadata":{"id":"zWVe8V2hp9fV"},"id":"zWVe8V2hp9fV","execution_count":null,"outputs":[]},{"cell_type":"code","source":["def ssim_loss(y_true, y_pred):\n","    return 1 - K.mean(tf.image.ssim(y_true, y_pred, max_val=1.0))"],"metadata":{"id":"vxTHyfZSA-cW"},"id":"vxTHyfZSA-cW","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"id":"7bff5711-21e5-4f7c-83fd-fe6273231c82","metadata":{"id":"7bff5711-21e5-4f7c-83fd-fe6273231c82"},"outputs":[],"source":["def loss_function(y_true, y_pred, lmbda=0.1, max_depth_value=MAX_DEPTH):\n","    '''\n","    Custom loss Fn\n","\n","    Arguments:\n","        y_true, y_pred -- according to tf, ground truth and model prediction\n","        lmbda -- MAE loss weight (0.1 default)\n","        max_depth_value -- max depth occurring anywhere in the image\n","    Returns\n","        Weighted sum of the 3 loss terms\n","    '''\n","\n","    # point-wise depth loss (MAE term)\n","    l_MAE = K.mean(K.abs(y_pred - y_true), axis=-1)\n","\n","    # gradient loss\n","    dy_true, dx_true = tf.image.image_gradients(y_true)\n","    dy_pred, dx_pred = tf.image.image_gradients(y_pred)\n","    l_edges = K.mean(K.abs(dy_pred - dy_true) + K.abs(dx_pred - dx_true), axis=-1)\n","\n","    # l_ssim term\n","    l_ssim = K.clip((1 - tf.image.ssim(y_true, y_pred, max_depth_value)) * 0.5, 0, 1)\n","\n","    return 0.85*l_ssim + 0.9*K.mean(l_edges) + lmbda*K.mean(l_MAE)"]},{"cell_type":"code","execution_count":null,"id":"42f622fb","metadata":{"scrolled":true,"id":"42f622fb"},"outputs":[],"source":["densenet = DenseNet169(include_top=False, input_shape=(96, 128, 3))\n","densenet.layers[-1].output[0].shape[-1]//2"]},{"cell_type":"code","execution_count":null,"id":"e796e8af-91c8-44cf-a6db-dc5445060367","metadata":{"id":"e796e8af-91c8-44cf-a6db-dc5445060367"},"outputs":[],"source":["def M_Unet(input_size=(96, 128, 3), n_filters=32, fine_tune=False, fine_tune_at=None):\n","    '''\n","    Transfer learning model. Call the base model DenseNet169, feed its output to our upsampling layers\n","\n","    Arguments:\n","        inputs_size -- size of input\n","        n_filters -- # of filters\n","        fine_tune (bool) -- whether to unlock layers of the base for fine tuning\n","        fine_tune_at (int) -- how many layers to unlock. ignored if fine_tune=False\n","    Returns:\n","        tf.keras.Model instance\n","    '''\n","\n","    # load the base model and freeze it\n","    inputs = tfl.Input(input_size)\n","\n","    base_model = DenseNet169(include_top=False, weights='imagenet', input_shape=input_size, input_tensor=inputs)\n","    base_model.trainable=False\n","\n","    # option to fine tune the model\n","    if fine_tune:\n","        base_model.trainable=True\n","        for layer in base_model.layers[:fine_tune_at]:\n","            layer.trainable = False\n","\n","    # grab the names of the concat layers\n","    concat_layers = ['pool1', 'pool2_pool', 'pool3_pool', 'conv1_relu']\n","\n","    mid = base_model(inputs, training=False)\n","\n","    # u net for the depth estimation\n","    bottleneck = tfl.Conv2D(n_filters*16, kernel_size=1, padding=\"same\")(mid)\n","    ublock1 = UpScaleBlock(bottleneck, base_model.get_layer(concat_layers[2]).output, n_filters=n_filters*8)\n","    ublock2 = UpScaleBlock(ublock1, base_model.get_layer(concat_layers[1]).output, n_filters=n_filters*4)\n","    ublock3 = UpScaleBlock(ublock2, base_model.get_layer(concat_layers[0]).output, n_filters=n_filters*2)\n","    ublock4 = UpScaleBlock(ublock3, base_model.get_layer(concat_layers[3]).output, n_filters=n_filters)\n","    ublock5 = UpScaleBlock(ublock4, None, concat=False)\n","\n","    outputs_depth = tfl.Conv2D(filters=1, kernel_size=3, strides=1, padding='same', activation='linear', name='depth')(ublock5)\n","\n","    # classification layer for common objects\n","    poolblock = tfl.GlobalAveragePooling2D()(mid)\n","    dropout = tfl.Dropout(0.2)(poolblock)\n","\n","    outputs_classifier = tfl.Dense(3, activation='softmax', name='classes')(dropout)\n","\n","    model = tf.keras.Model(inputs=inputs, outputs={'depth': outputs_depth, 'classes': outputs_classifier})\n","    print(inputs, '\\n', outputs_depth, '\\n',  outputs_classifier)\n","    return model\n"]},{"cell_type":"code","execution_count":null,"id":"37860661-4b19-47af-ac81-f4030d997b8d","metadata":{"scrolled":true,"id":"37860661-4b19-47af-ac81-f4030d997b8d"},"outputs":[],"source":["# grab the model and print its summary\n","model = M_Unet(n_filters=(832//16))\n","model.summary(show_trainable=True, line_length=100)"]},{"cell_type":"code","execution_count":null,"id":"3b9acdeb-1405-40d0-8bcf-a11b0b4f7e26","metadata":{"id":"3b9acdeb-1405-40d0-8bcf-a11b0b4f7e26"},"outputs":[],"source":["# compile the model with a learning rate decay scheduler\n","scheduler = tf.keras.optimizers.schedules.ExponentialDecay(0.0001, decay_steps=50, decay_rate=0.99, staircase=True)\n","optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001, amsgrad=True)\n","\n","model.compile(optimizer=optimizer,\n","              loss={\n","                  'depth': loss_function,\n","                  'classes': 'sparse_categorical_crossentropy'\n","              },\n","              metrics={\n","                  'depth': [ssim_loss,'mae'],\n","                  'classes': [SparseCategoricalAccuracy(name='accuracy')]\n","                  #'classes': tf.metrics.SparseCategoricalAccuracy\n","              })"]},{"cell_type":"code","execution_count":null,"id":"61f1c7d2-d105-4613-92dc-def808b59a47","metadata":{"id":"61f1c7d2-d105-4613-92dc-def808b59a47"},"outputs":[],"source":["EPOCHS = 30\n","BATCH_SIZE = 16\n","tf.keras.config.disable_traceback_filtering()\n","\n","\n","# save the model at the best\n","checkpoint_path = \".tf_checkpoints/checkpoint-resnet-test-{epoch:04d}.keras\" #(Paul): If save_weights_only=False\n","#checkpoint_path = '.tf_checkpoints/checkpoint-resnet-test-{epoch:04d}.weights.h5' #(Paul): If save_weights_only=True\n","checkpoint_dir = os.path.dirname(checkpoint_path)\n","\n","checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n","                                                         verbose=1,\n","                                                         save_weights_only=False, #(Paul): This was originally \"True\"\n","                                                         save_best_only=True)\n","\n","# train the model\n","history = model.fit(X_train,\n","                    {\n","                        'depth': Y_train,\n","                        'classes': classes_train\n","                    },\n","                    batch_size=BATCH_SIZE,\n","                    epochs=EPOCHS,\n","                    callbacks=[checkpoint_callback],\n","                    validation_split=0.1)\n"]},{"cell_type":"code","source":["# save the model\n","model.save_weights('/content/drive/MyDrive/CS230 /model-11-30-2024.weights.h5')"],"metadata":{"id":"HXJovXBFVkhO"},"id":"HXJovXBFVkhO","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# load the model and continue to train it\n","new_model = M_Unet(n_filters=(832//16))\n","new_model.load_weights('/content/drive/MyDrive/CS230 /model-11-30-2024.weights.h5')\n","\n","scheduler = tf.keras.optimizers.schedules.ExponentialDecay(0.0001, decay_steps=1000, decay_rate=0.9, staircase=True)\n","optimizer = tf.keras.optimizers.Adam(learning_rate=scheduler, amsgrad=True)\n","\n","new_model.compile(optimizer=optimizer,\n","              loss={\n","                  'depth': loss_function,\n","                  'classes': 'sparse_categorical_crossentropy'\n","              },\n","              metrics={\n","                  'depth': 'mae',\n","                  'ssim': ssim_metric,\n","                  'classes': tf.metrics.SparseCategoricalAccuracy\n","              })"],"metadata":{"id":"KfpCPk87V76t"},"id":"KfpCPk87V76t","execution_count":null,"outputs":[]},{"cell_type":"code","source":["EPOCHS = 100\n","BATCH_SIZE = 16\n","tf.keras.config.disable_traceback_filtering()\n","\n","\n","# save the model at the best\n","checkpoint_path = \"/content/drive/MyDrive/CS230 /model-11-30-2024-continuation-00.weights.h5\"\n","checkpoint_dir = os.path.dirname(checkpoint_path)\n","\n","checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n","                                                         verbose=1,\n","                                                         save_weights_only=True,\n","                                                         save_best_only=True)\n","\n","\n","# train the model\n","history = new_model.fit(X_train,\n","                    {\n","                        'depth': Y_train,\n","                        'classes': classes_train\n","                    },\n","                    batch_size=BATCH_SIZE,\n","                    epochs=EPOCHS,\n","                    initial_epoch=30,\n","                    callbacks=[checkpoint_callback],\n","                    validation_split=0.1)"],"metadata":{"id":"H4olCF8pWXjK"},"id":"H4olCF8pWXjK","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"id":"bf0c7f29-6435-4f2a-a250-c74fe176d8ac","metadata":{"id":"bf0c7f29-6435-4f2a-a250-c74fe176d8ac"},"outputs":[],"source":["print(history.history.keys())\n","plt.plot(history.history['loss'], label='Loss')\n","\n","#plt.plot(history.history['classes_loss'], label='Classes Loss')\n","#plt.plot(history.history['classes_sparse_categorical_accuracy'], label='Classes Accuracy')\n","\n","plt.plot(history.history['depth_loss'], label='Depth Loss')\n","plt.plot(history.history['depth_mae'], label='Depth MAE')\n","plt.plot(history.history['ssim_metric'], label='Depth SSIM')\n","\n","plt.title('Pushing the loss down for 70 more epochs')\n","plt.xlabel('epochs')\n","plt.legend()\n","plt.show()\n","plt.savefig('/content/drive/MyDrive/CS230 /Figures/stagnated-learning.jpg')"]},{"cell_type":"code","execution_count":null,"id":"38d90678-31d1-4914-a581-54791db38a8c","metadata":{"id":"38d90678-31d1-4914-a581-54791db38a8c"},"outputs":[],"source":["def show_predictions(images, ground_truth, nums=[0, 1, 2]):\n","    '''\n","    Cute wrapper to pick an image, show its GT and prediction. Use on train or test set\n","\n","    Arguments:\n","    images -- RGB image\n","    ground_truth -- GT depth\n","    num -- index of the image you want to predict\n","\n","    TODO: add functionality for showing predictions of images without GT\n","\n","    Returns:\n","    Nothing. Shows plt.figure on call\n","    '''\n","\n","    fig, arr = plt.subplots(len(nums), 3, figsize=(12, len(nums)*4))\n","\n","    for i in range(len(nums)):\n","      test_predict = np.reshape(images[nums[i]], (1, 96, 128, 3))\n","      test_truth = np.reshape(ground_truth[nums[i]], (1, 96, 128, 1))\n","      prediction = new_model.predict(test_predict)\n","\n","      arr[i, 0].imshow(images[nums[i]])\n","      arr[i, 0].set_title('Original Image')\n","\n","      vmax, vmin = np.max(ground_truth[nums[i]]), np.min(ground_truth[nums[i]])\n","\n","      arr[i, 1].imshow(ground_truth[nums[i]], cmap=cmap, vmax=vmax, vmin=vmin)\n","      arr[i, 1].set_title('Ground Truth Map')\n","\n","      arr[i, 2].imshow(prediction['depth'][0, :, :, :], cmap=cmap, vmax=vmax, vmin=vmin)\n","      arr[i, 2].set_title('Predicted Map')\n","      class_prediction = np.argmax(prediction['classes'][0])\n","\n","      print(f'the model thinks this image number {nums[i]} is a {decode_class(class_prediction)}')"]},{"cell_type":"code","execution_count":null,"id":"48254538-af0c-4cef-be4d-5ef8088bc90a","metadata":{"id":"48254538-af0c-4cef-be4d-5ef8088bc90a"},"outputs":[],"source":["show_predictions(X_train, Y_train, nums=[90, 878, 326, 57, 267, 264])"]},{"cell_type":"code","execution_count":null,"id":"ccdc0057","metadata":{"id":"ccdc0057"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.6"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":5}